{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importo las librerias necesarias para esta parte del proyecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import json\n",
    "from collections import namedtuple\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos extraidos de la web de la [AEMET](https://opendata.aemet.es/centrodedescargas/productosAEMET?), usanso el API key que me proporcionaron al registrarme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extraigo los datos de 3 años, desde el 01-01-2018 hasta el 31-12-2020 y lo almaceno en un JSON\n",
    "#### La estacion meteorologica que me ha proporcionado los datos, esta situada en Ciudad Universitaria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Voy a usar los siguientes datos proporcionados por la AEMET: \n",
    "- Fecha: `fecha`\n",
    "- Temperatura Media: `tmed`\n",
    "- Temperatura Minima: `tmin`\n",
    "- Temperatura Maxima: `tmax`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_archivo_json = 'datos.json'\n",
    "\n",
    "with open(ruta_archivo_json) as archivo_json:\n",
    "    datos_json = json.load(archivo_json)\n",
    "    \n",
    "df = pd.DataFrame(datos_json)\n",
    "df = df.set_index('fecha')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Debido a que no tengo demasiado conocimiento sobre climatologia, hare como en el tutorial proporcionado y usare informacion de los 3 dias anteriores para la prediccion. La intencion es añadir variables al modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Para cada dia (fila), y cada medida (columna) que tengo, voy a buscar el valor de esa medida N dias antes y creare una columna nueva para esa medida mediante una funcion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funcion que hace lo explicitado anteriormente\n",
    "def derive_nth_day_feature(df, feature, N):\n",
    "    rows = df.shape[0]\n",
    "    nth_prior_measurements = [None]*N + [df[feature][i-N] for i in range(N, rows)]\n",
    "    col_name = \"{}_{}\".format(feature, N)\n",
    "    df[col_name] = nth_prior_measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A continuacion, mediante un bucle, aplicare toda la funcion al dataframe principal\n",
    "#### Con estos nuevos datos podre predecir mucho mejor el clima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['tmed', 'prec', 'tmin', 'tmax']\n",
    "for feature in features:\n",
    "    if feature != 'date':\n",
    "        for N in range(1, 4):\n",
    "            derive_nth_day_feature(df, feature, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['indicativo', 'nombre', 'provincia', 'altitud', 'tmed', 'prec', 'tmin',\n",
       "       'horatmin', 'tmax', 'horatmax', 'dir', 'velmedia', 'racha', 'horaracha',\n",
       "       'tmed_1', 'tmed_2', 'tmed_3', 'prec_1', 'prec_2', 'prec_3', 'tmin_1',\n",
       "       'tmin_2', 'tmin_3', 'tmax_1', 'tmax_2', 'tmax_3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Columnas resultantes\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elimino las columnas que no voy a necesitar, de esta manera trabajare con menos datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['prec','indicativo','nombre','provincia','altitud','horatmin','horatmax','dir','velmedia','racha','horaracha'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1089 entries, 2018-01-01 to 2020-12-31\n",
      "Data columns (total 15 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   tmed    938 non-null    object\n",
      " 1   tmin    938 non-null    object\n",
      " 2   tmax    938 non-null    object\n",
      " 3   tmed_1  937 non-null    object\n",
      " 4   tmed_2  936 non-null    object\n",
      " 5   tmed_3  935 non-null    object\n",
      " 6   prec_1  1084 non-null   object\n",
      " 7   prec_2  1083 non-null   object\n",
      " 8   prec_3  1082 non-null   object\n",
      " 9   tmin_1  937 non-null    object\n",
      " 10  tmin_2  936 non-null    object\n",
      " 11  tmin_3  935 non-null    object\n",
      " 12  tmax_1  937 non-null    object\n",
      " 13  tmax_2  936 non-null    object\n",
      " 14  tmax_3  935 non-null    object\n",
      "dtypes: object(15)\n",
      "memory usage: 136.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Como se puede observar, lo siguiente a realizar es dar el formato adecuado a las columnas del dataframe, usare para ello el metodo `to_numeric` de pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1089 entries, 2018-01-01 to 2020-12-31\n",
      "Data columns (total 15 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   tmed    938 non-null    float64\n",
      " 1   tmin    938 non-null    float64\n",
      " 2   tmax    938 non-null    float64\n",
      " 3   tmed_1  937 non-null    float64\n",
      " 4   tmed_2  936 non-null    float64\n",
      " 5   tmed_3  935 non-null    float64\n",
      " 6   prec_1  1084 non-null   float64\n",
      " 7   prec_2  1083 non-null   float64\n",
      " 8   prec_3  1082 non-null   float64\n",
      " 9   tmin_1  937 non-null    float64\n",
      " 10  tmin_2  936 non-null    float64\n",
      " 11  tmin_3  935 non-null    float64\n",
      " 12  tmax_1  937 non-null    float64\n",
      " 13  tmax_2  936 non-null    float64\n",
      " 14  tmax_3  935 non-null    float64\n",
      "dtypes: float64(15)\n",
      "memory usage: 136.1+ KB\n"
     ]
    }
   ],
   "source": [
    "#Lo primero es sustituir las comas por puntos\n",
    "df = (df.replace(',','.', regex=True).astype(float))\n",
    "#Ahora convierto a un tipo de dato numerico\n",
    "df = df.apply(pd.to_numeric, errors='coerce')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ahora que tengo el dataframe con el formato adecuado, tengo que utilizar reglas estadisticas para ver si hay casos extremos. \n",
    "\n",
    "#### Usare para ello la funcion `describe()` que me proporcionara varios datos estadisticos como la media, los percentiles etc...\n",
    "\n",
    "#### Esta informacion es muy util para saber la distribucion de los datos\n",
    "\n",
    "#### Añadire otra columna (outliers) que indicara si en esa columna hay outliers, es decir, valores extremos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>outliers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>prec_1</th>\n",
       "      <td>1084.0</td>\n",
       "      <td>1.194926</td>\n",
       "      <td>4.034098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>43.8</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prec_2</th>\n",
       "      <td>1083.0</td>\n",
       "      <td>1.196030</td>\n",
       "      <td>4.035798</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>43.8</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prec_3</th>\n",
       "      <td>1082.0</td>\n",
       "      <td>1.197135</td>\n",
       "      <td>4.037500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>43.8</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count      mean       std  min  25%  50%  75%   max  outliers\n",
       "prec_1  1084.0  1.194926  4.034098  0.0  0.0  0.0  0.1  43.8      True\n",
       "prec_2  1083.0  1.196030  4.035798  0.0  0.0  0.0  0.1  43.8      True\n",
       "prec_3  1082.0  1.197135  4.037500  0.0  0.0  0.0  0.1  43.8      True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Llamo a decribe() para ver el df y lo transpongo para mejorar su visualizacion\n",
    "spread = df.describe().T\n",
    "\n",
    "#Precalculo el rango intercuartilico ya que me sera util para los proximos calculos\n",
    "IQR = spread['75%'] - spread['25%']\n",
    "\n",
    "# Creo la columna de outliers\n",
    "spread['outliers'] = (spread['min']<(spread['25%']-(3*IQR)))|(spread['max'] > (spread['75%']+3*IQR))\n",
    "\n",
    "# Muestro solamente las medidas que tiene outliers\n",
    "spread.loc[spread.outliers,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Es muy complicado evaluar el impacto potencial de estos outliers\n",
    "\n",
    "#### Por un lado, puede que añadan datos erroneos(espuria) que tengan un impacto significativo en el modelo\n",
    "\n",
    "#### En cambio, me pueden ser tremendamente utiles para predecir algunos resultados que ocurren bajo unas determinadas circunstancias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### En este caso, al tratarse de la precipitacion, es muy comprensible la presencia de outliers. Debido a que los dias con 0% de precipitacion son muy frecuentes. Por este motivo, mantendre los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finalmente, debo decidir que hacer con los datos que faltan, que estan representados como NaNs. Ya que la ausencia de datos, puede ser un problema para los metodos de machine learning.\n",
    "\n",
    "#### Muchos de ellos se deben a las primeras filas, ya que no hay datos anteriores. Elimino esas filas.\n",
    "\n",
    "#### Viendo el resultado de `df.info()` se observa que en todas las columnas faltan unos 140 datos, excepto en las precipitaciones que estan practicamente completas.\n",
    "\n",
    "### Tengo dos opciones, eliminar esas filas, o rellenarlas haciendo interpolacion.\n",
    "#### Debido a que la interpolacion no sera facil, he decidido eliminarlas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 912 entries, 2018-01-04 to 2020-12-31\n",
      "Data columns (total 15 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   tmed    912 non-null    float64\n",
      " 1   tmin    912 non-null    float64\n",
      " 2   tmax    912 non-null    float64\n",
      " 3   tmed_1  912 non-null    float64\n",
      " 4   tmed_2  912 non-null    float64\n",
      " 5   tmed_3  912 non-null    float64\n",
      " 6   prec_1  912 non-null    float64\n",
      " 7   prec_2  912 non-null    float64\n",
      " 8   prec_3  912 non-null    float64\n",
      " 9   tmin_1  912 non-null    float64\n",
      " 10  tmin_2  912 non-null    float64\n",
      " 11  tmin_3  912 non-null    float64\n",
      " 12  tmax_1  912 non-null    float64\n",
      " 13  tmax_2  912 non-null    float64\n",
      " 14  tmax_3  912 non-null    float64\n",
      "dtypes: float64(15)\n",
      "memory usage: 114.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finalmente, tengo 912 columnas, en lugar de las 1089 iniciales, no es excesivo el corte que he hecho"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -----------------------EXPORTACION DE DATOS----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv (r'end-part1.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('end-part1_df.pkl', 'wb') as fp:\n",
    "    pickle.dump(df, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
